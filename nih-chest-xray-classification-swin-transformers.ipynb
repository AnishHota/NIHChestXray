{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NIH Chest X-ray using different swin architectures","metadata":{}},{"cell_type":"markdown","source":"### Importing libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-03-24T02:29:47.308765Z","iopub.execute_input":"2023-03-24T02:29:47.309811Z","iopub.status.idle":"2023-03-24T02:29:47.315913Z","shell.execute_reply.started":"2023-03-24T02:29:47.309749Z","shell.execute_reply":"2023-03-24T02:29:47.314645Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchmetrics","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:29:50.284231Z","iopub.execute_input":"2023-03-24T02:29:50.285222Z","iopub.status.idle":"2023-03-24T02:30:00.642693Z","shell.execute_reply.started":"2023-03-24T02:29:50.285166Z","shell.execute_reply":"2023-03-24T02:30:00.641414Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:30:00.646967Z","iopub.execute_input":"2023-03-24T02:30:00.648010Z","iopub.status.idle":"2023-03-24T02:30:00.729826Z","shell.execute_reply.started":"2023-03-24T02:30:00.647964Z","shell.execute_reply":"2023-03-24T02:30:00.728765Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"### Creating the Dataset","metadata":{}},{"cell_type":"code","source":"label_map = {'Atelectasis': 0,\n             'Cardiomegaly': 1,\n             'Effusion': 2,\n             'Infiltration': 3,\n             'Mass': 4,\n             'Nodule': 5,\n             'Pneumonia': 6,\n             'Pneumothorax': 7,\n             'Consolidation': 8,\n             'Edema': 9,\n             'Emphysema': 10,\n             'Fibrosis': 11,\n             'Pleural_Thickening': 12,\n             'Hernia': 13,\n             'No Finding': 14}\nlen(label_map)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:30:26.283888Z","iopub.execute_input":"2023-03-24T02:30:26.284283Z","iopub.status.idle":"2023-03-24T02:30:26.292628Z","shell.execute_reply.started":"2023-03-24T02:30:26.284250Z","shell.execute_reply":"2023-03-24T02:30:26.291516Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"15"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport pandas as pd\nfrom PIL import Image\nclass NIH_Chest_Xray_Dataset(Dataset):\n    def __init__(self, data_dir, train_test_file, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.train_test_file = train_test_file\n        train_test_img_list = [line.rstrip() for line in open(train_test_file)]\n        # Read the CSV file with the image labels\n        df = pd.read_csv(os.path.join(data_dir, 'Data_Entry_2017.csv'))\n\n        # Loop through the images and labels, and store the paths and labels in lists  \n        \n        for i, row in df.iterrows():\n            img_name = row['Image Index']\n            if img_name in train_test_img_list:\n                for i in range (1,13):\n                #for i in range (1,2):    \n                    img_path = os.path.join(data_dir,f'images_00{i}/images/',img_name)\n                \n                    if os.path.isfile(img_path):\n                        self.image_paths.append(img_path)\n                        label = row['Finding Labels'].split(\"|\")\n                        self.labels.append(label)\n                        break\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        \n        # Open the image file and apply the transforms (if any)\n        img = Image.open(img_path).convert('RGB')\n        if self.transform is not None:\n            img = self.transform(img)\n\n        num_labels = 15 # There are 14 possible labels in the dataset\n        binary_label = torch.zeros(num_labels)\n        \n        for l in label:\n            binary_label[label_map[l]] = 1\n\n        return img, binary_label","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:30:18.996654Z","iopub.execute_input":"2023-03-24T02:30:18.997726Z","iopub.status.idle":"2023-03-24T02:30:19.009850Z","shell.execute_reply.started":"2023-03-24T02:30:18.997687Z","shell.execute_reply":"2023-03-24T02:30:19.008724Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets, transforms\ndata_dir = '/kaggle/input/data/'\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\ntrain_file = os.path.join(data_dir, 'train_val_list.txt')\ntest_file = os.path.join(data_dir, 'test_list.txt')\ntrain_dataset = NIH_Chest_Xray_Dataset(data_dir, train_test_file=train_file, transform=transform)\nprint(len(train_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:30:29.648358Z","iopub.execute_input":"2023-03-24T02:30:29.649097Z","iopub.status.idle":"2023-03-24T02:37:38.522991Z","shell.execute_reply.started":"2023-03-24T02:30:29.649057Z","shell.execute_reply":"2023-03-24T02:37:38.521748Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"67091\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset = NIH_Chest_Xray_Dataset(data_dir, train_test_file=test_file, transform=transform)\nprint(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:37:38.525588Z","iopub.execute_input":"2023-03-24T02:37:38.525989Z","iopub.status.idle":"2023-03-24T02:40:04.659173Z","shell.execute_reply.started":"2023-03-24T02:37:38.525950Z","shell.execute_reply":"2023-03-24T02:40:04.657881Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"17908\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n\ntest_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:40:04.660718Z","iopub.execute_input":"2023-03-24T02:40:04.661227Z","iopub.status.idle":"2023-03-24T02:40:04.668044Z","shell.execute_reply.started":"2023-03-24T02:40:04.661184Z","shell.execute_reply":"2023-03-24T02:40:04.666930Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:40:04.670770Z","iopub.execute_input":"2023-03-24T02:40:04.671954Z","iopub.status.idle":"2023-03-24T02:40:04.678619Z","shell.execute_reply.started":"2023-03-24T02:40:04.671908Z","shell.execute_reply":"2023-03-24T02:40:04.677532Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# from torchvision.models import swin_t\nfrom torchvision.models import swin_b\n# from torchvision.models import swin_s","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:40:04.680349Z","iopub.execute_input":"2023-03-24T02:40:04.680780Z","iopub.status.idle":"2023-03-24T02:40:04.686774Z","shell.execute_reply.started":"2023-03-24T02:40:04.680729Z","shell.execute_reply":"2023-03-24T02:40:04.685490Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Run-1 with Swin tiny without weights","metadata":{}},{"cell_type":"code","source":"from torchvision.models import swin_t\n# Use a pre-trained imagenet\n#model = swin_t(weights='DEFAULT')\n# Use no weights\nmodel = swin_t()\n\n# Update the fully connected layer based on the number of classes in the dataset\n#model.fc = torch.nn.Linear(model.fc.in_features, len(ds_train.labels.info.class_names))\nmodel.head = torch.nn.Linear(out_features=15,in_features=768)\n\nmodel.to(device)\n\nprint(model)\n# Specity the loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:47:19.021535Z","iopub.execute_input":"2023-03-01T21:47:19.021962Z","iopub.status.idle":"2023-03-01T21:47:22.474346Z","shell.execute_reply.started":"2023-03-01T21:47:19.021925Z","shell.execute_reply":"2023-03-01T21:47:22.473169Z"},"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n#train\nmodel.train()\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    \n    running_loss = 0.0\n    for images, labels in tqdm(train_dataloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n    epoch_loss = running_loss / len(train_dataset)\n    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:47:40.534823Z","iopub.execute_input":"2023-03-01T21:47:40.535769Z","iopub.status.idle":"2023-03-01T23:56:59.561938Z","shell.execute_reply.started":"2023-03-01T21:47:40.535717Z","shell.execute_reply":"2023-03-01T23:56:59.560667Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate\nmodel.eval()\n    \nrunning_loss = 0.0\nrunning_corrects = torch.zeros(15).to(device)\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tqdm(test_dataloader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item() * inputs.size(0)\n        predicted_labels = torch.sigmoid(outputs) > 0.5\n        running_corrects += (predicted_labels == labels).sum(dim=0).float()\n        total_samples += inputs.size(0)\n\nepoch_loss = running_loss / total_samples\nepoch_acc = running_corrects / total_samples\n\nprint(f'Validation Loss: {epoch_loss:.4f} | Validation Acc: {epoch_acc.tolist()}')","metadata":{"execution":{"iopub.status.busy":"2023-03-02T00:04:46.922656Z","iopub.execute_input":"2023-03-02T00:04:46.923320Z","iopub.status.idle":"2023-03-02T00:11:15.315068Z","shell.execute_reply.started":"2023-03-02T00:04:46.923259Z","shell.execute_reply":"2023-03-02T00:11:15.311761Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run-2: Swin tiny with imagenet weights","metadata":{}},{"cell_type":"code","source":"# Use a pre-trained imagenet\n#model = swin_t(weights='DEFAULT')\n# Use no weights\nmodel_pre_1 = swin_t(weights='DEFAULT')\n\n# Update the fully connected layer based on the number of classes in the dataset\n#model.fc = torch.nn.Linear(model.fc.in_features, len(ds_train.labels.info.class_names))\nmodel_pre_1.head = torch.nn.Linear(out_features=15,in_features=768)\n\nmodel_pre_1.to(device)\n\nprint(model_pre_1)\n\n# Specity the loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model_pre_1.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2023-03-02T16:09:36.582701Z","iopub.execute_input":"2023-03-02T16:09:36.583707Z","iopub.status.idle":"2023-03-02T16:09:46.270035Z","shell.execute_reply.started":"2023-03-02T16:09:36.583668Z","shell.execute_reply":"2023-03-02T16:09:46.268998Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n#train\nmodel_pre_1.train()\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    \n    running_loss = 0.0\n    for images, labels in tqdm(train_dataloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model_pre_1(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n    epoch_loss = running_loss / len(train_dataset)\n    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))","metadata":{"execution":{"iopub.status.busy":"2023-03-02T16:10:10.345127Z","iopub.execute_input":"2023-03-02T16:10:10.345821Z","iopub.status.idle":"2023-03-02T18:16:26.651405Z","shell.execute_reply.started":"2023-03-02T16:10:10.345784Z","shell.execute_reply":"2023-03-02T18:16:26.648769Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate\nmodel_pre_1.eval()\n    \nrunning_loss = 0.0\nrunning_corrects = torch.zeros(15).to(device)\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tqdm(test_dataloader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model_pre_1(inputs)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item() * inputs.size(0)\n        predicted_labels = torch.sigmoid(outputs) > 0.5\n        running_corrects += (predicted_labels == labels).sum(dim=0).float()\n        total_samples += inputs.size(0)\n\nepoch_loss = running_loss / total_samples\nepoch_acc = running_corrects / total_samples\n\nprint(f'Validation Loss: {epoch_loss:.4f} | Validation Acc: {epoch_acc.tolist()}')","metadata":{"execution":{"iopub.status.busy":"2023-03-02T18:16:26.656481Z","iopub.execute_input":"2023-03-02T18:16:26.656837Z","iopub.status.idle":"2023-03-02T18:22:55.525202Z","shell.execute_reply.started":"2023-03-02T18:16:26.656803Z","shell.execute_reply":"2023-03-02T18:22:55.523907Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run-3: Swin base without weights","metadata":{}},{"cell_type":"code","source":"from torchvision.models import swin_b","metadata":{"execution":{"iopub.status.busy":"2023-03-02T06:16:19.444611Z","iopub.execute_input":"2023-03-02T06:16:19.445631Z","iopub.status.idle":"2023-03-02T06:16:19.450534Z","shell.execute_reply.started":"2023-03-02T06:16:19.445591Z","shell.execute_reply":"2023-03-02T06:16:19.449408Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use a pre-trained imagenet\n#model = swin_t(weights='DEFAULT')\n# Use no weights\nmodel_base_1 = swin_b()\n\n# Update the fully connected layer based on the number of classes in the dataset\n#model.fc = torch.nn.Linear(model.fc.in_features, len(ds_train.labels.info.class_names))\nmodel_base_1.head = torch.nn.Linear(out_features=15,in_features=1024)\n\nmodel_base_1.to(device)\n\nprint(model_base_1)","metadata":{"execution":{"iopub.status.busy":"2023-03-02T06:21:19.071490Z","iopub.execute_input":"2023-03-02T06:21:19.072103Z","iopub.status.idle":"2023-03-02T06:21:21.258994Z","shell.execute_reply.started":"2023-03-02T06:21:19.072067Z","shell.execute_reply":"2023-03-02T06:21:21.257710Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model_base_1.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2023-03-02T06:21:27.345708Z","iopub.execute_input":"2023-03-02T06:21:27.346327Z","iopub.status.idle":"2023-03-02T06:21:27.353220Z","shell.execute_reply.started":"2023-03-02T06:21:27.346286Z","shell.execute_reply":"2023-03-02T06:21:27.352106Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n#train\nmodel_base_1.train()\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    \n    running_loss = 0.0\n    for images, labels in tqdm(train_dataloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model_base_1(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n    epoch_loss = running_loss / len(train_dataset)\n    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))","metadata":{"execution":{"iopub.status.busy":"2023-03-02T06:21:37.792615Z","iopub.execute_input":"2023-03-02T06:21:37.793320Z","iopub.status.idle":"2023-03-02T08:57:16.136691Z","shell.execute_reply.started":"2023-03-02T06:21:37.793279Z","shell.execute_reply":"2023-03-02T08:57:16.133629Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate\nmodel_base_1.eval()\n    \nrunning_loss = 0.0\nrunning_corrects = torch.zeros(15).to(device)\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tqdm(test_dataloader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model_base_1(inputs)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item() * inputs.size(0)\n        predicted_labels = torch.sigmoid(outputs) > 0.5\n        running_corrects += (predicted_labels == labels).sum(dim=0).float()\n        total_samples += inputs.size(0)\n\nepoch_loss = running_loss / total_samples\nepoch_acc = running_corrects / total_samples\n\nprint(f'Validation Loss: {epoch_loss:.4f} | Validation Acc: {epoch_acc.tolist()}')","metadata":{"execution":{"iopub.status.busy":"2023-03-02T11:47:54.979737Z","iopub.execute_input":"2023-03-02T11:47:54.980038Z","iopub.status.idle":"2023-03-02T11:54:20.795292Z","shell.execute_reply.started":"2023-03-02T11:47:54.980004Z","shell.execute_reply":"2023-03-02T11:54:20.794049Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run-4: Swin base with imagenet weights","metadata":{}},{"cell_type":"code","source":"# Use a pre-trained imagenet\n#model = swin_t(weights='DEFAULT')\n# Use no weights\nmodel_base_pre_1 = swin_b(weights='DEFAULT')\n\n# Update the fully connected layer based on the number of classes in the dataset\n#model.fc = torch.nn.Linear(model.fc.in_features, len(ds_train.labels.info.class_names))\nmodel_base_pre_1.head = torch.nn.Linear(out_features=15,in_features=1024)\n\nmodel_base_pre_1.to(device)\n\nprint(model_base_pre_1)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model_base_pre_1.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:40:04.688476Z","iopub.execute_input":"2023-03-24T02:40:04.688993Z","iopub.status.idle":"2023-03-24T02:40:12.105842Z","shell.execute_reply.started":"2023-03-24T02:40:04.688956Z","shell.execute_reply":"2023-03-24T02:40:12.104664Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"SwinTransformer(\n  (features): Sequential(\n    (0): Sequential(\n      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n      (1): Permute()\n      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    )\n    (1): Sequential(\n      (0): SwinTransformerBlock(\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=128, out_features=384, bias=True)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=128, out_features=512, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=512, out_features=128, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): SwinTransformerBlock(\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=128, out_features=384, bias=True)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.021739130434782608, mode=row)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=128, out_features=512, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=512, out_features=128, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (2): PatchMerging(\n      (reduction): Linear(in_features=512, out_features=256, bias=False)\n      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (3): Sequential(\n      (0): SwinTransformerBlock(\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=256, out_features=768, bias=True)\n          (proj): Linear(in_features=256, out_features=256, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=256, out_features=1024, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=1024, out_features=256, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): SwinTransformerBlock(\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=256, out_features=768, bias=True)\n          (proj): Linear(in_features=256, out_features=256, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=256, out_features=1024, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=1024, out_features=256, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (4): PatchMerging(\n      (reduction): Linear(in_features=1024, out_features=512, bias=False)\n      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (5): Sequential(\n      (0): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.10869565217391304, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (3): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.15217391304347827, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (4): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (5): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (6): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.21739130434782608, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (7): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.2391304347826087, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (8): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (9): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.2826086956521739, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (10): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.30434782608695654, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (11): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.32608695652173914, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (12): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.34782608695652173, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (13): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.3695652173913043, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (14): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.391304347826087, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (15): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.41304347826086957, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (16): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.43478260869565216, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (17): SwinTransformerBlock(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.45652173913043476, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (6): PatchMerging(\n      (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n      (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n    )\n    (7): Sequential(\n      (0): SwinTransformerBlock(\n        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.4782608695652174, mode=row)\n        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=4096, out_features=1024, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): SwinTransformerBlock(\n        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttention(\n          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        )\n        (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=4096, out_features=1024, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n  )\n  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  (permute): Permute()\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (head): Linear(in_features=1024, out_features=15, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchmetrics import AUROC","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:40:12.107841Z","iopub.execute_input":"2023-03-24T02:40:12.108257Z","iopub.status.idle":"2023-03-24T02:40:12.115514Z","shell.execute_reply.started":"2023-03-24T02:40:12.108215Z","shell.execute_reply":"2023-03-24T02:40:12.114501Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"ml_auroc = AUROC(task=\"multilabel\",num_labels=15, average=\"macro\", thresholds=None)\nroc_auc_score = []","metadata":{"execution":{"iopub.status.busy":"2023-03-24T02:40:12.117418Z","iopub.execute_input":"2023-03-24T02:40:12.117809Z","iopub.status.idle":"2023-03-24T02:40:12.129720Z","shell.execute_reply.started":"2023-03-24T02:40:12.117771Z","shell.execute_reply":"2023-03-24T02:40:12.128422Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n#train\nmodel_base_pre_1.train()\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    \n    running_loss = 0.0\n    running_roc_auc = 0.0\n\n    for images, labels in tqdm(train_dataloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model_base_pre_1(images)\n        loss = criterion(outputs, labels)\n        roc_auc = ml_auroc(outputs, labels.to(dtype=torch.long))\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)  \n        running_roc_auc += roc_auc\n\n    epoch_loss = running_loss / len(train_dataset)\n    epoch_roc_auc = running_roc_auc / len(train_dataset)\n    roc_auc_score.append(epoch_roc_auc)\n\n    print('Epoch [{}/{}], Loss: {:.4f}, ROC_AUC_Score: {:.4f}'.format(epoch+1, num_epochs, epoch_loss, epoch_roc_auc))","metadata":{"execution":{"iopub.status.busy":"2023-03-24T05:10:05.335683Z","iopub.execute_input":"2023-03-24T05:10:05.336326Z","iopub.status.idle":"2023-03-24T05:10:05.357222Z","shell.execute_reply.started":"2023-03-24T05:10:05.336286Z","shell.execute_reply":"2023-03-24T05:10:05.355335Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_8750/793363345.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_base_pre_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model_base_pre_1' is not defined"],"ename":"NameError","evalue":"name 'model_base_pre_1' is not defined","output_type":"error"}]},{"cell_type":"code","source":"#Evaluate\nmodel_base_pre_1.eval()\n    \nrunning_loss = 0.0\nrunning_corrects = torch.zeros(15).to(device)\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tqdm(test_dataloader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model_base_pre_1(inputs)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item() * inputs.size(0)\n        predicted_labels = torch.sigmoid(outputs) > 0.5\n        running_corrects += (predicted_labels == labels).sum(dim=0).float()\n        total_samples += inputs.size(0)\n\nepoch_loss = running_loss / total_samples\nepoch_acc = running_corrects / total_samples\n\n\nprint(f'Validation Loss: {epoch_loss:.4f} | Validation Acc: {epoch_acc.tolist()} | roc_auc_score: {}')","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:29:30.399910Z","iopub.execute_input":"2023-03-02T14:29:30.400375Z","iopub.status.idle":"2023-03-02T14:36:08.592189Z","shell.execute_reply.started":"2023-03-02T14:29:30.400308Z","shell.execute_reply":"2023-03-02T14:36:08.591052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run-5: Swin small from scratch","metadata":{}},{"cell_type":"code","source":"# Use a pre-trained imagenet\n#model = swin_t(weights='DEFAULT')\n# Use no weights\nmodel_small_1 = swin_s()\n\n# Update the fully connected layer based on the number of classes in the dataset\n#model.fc = torch.nn.Linear(model.fc.in_features, len(ds_train.labels.info.class_names))\nmodel_small_1.head = torch.nn.Linear(out_features=15,in_features=768)\n\nmodel_small_1.to(device)\n\nprint(model_small_1)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model_small_1.parameters(), lr=1e-4)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-03-03T00:24:28.013929Z","iopub.execute_input":"2023-03-03T00:24:28.014335Z","iopub.status.idle":"2023-03-03T00:24:29.279991Z","shell.execute_reply.started":"2023-03-03T00:24:28.014299Z","shell.execute_reply":"2023-03-03T00:24:29.277655Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n#train\nmodel_small_1.train()\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    \n    running_loss = 0.0\n    for images, labels in tqdm(train_dataloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model_small_1(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n    epoch_loss = running_loss / len(train_dataset)\n    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))","metadata":{"execution":{"iopub.status.busy":"2023-03-03T00:24:38.182689Z","iopub.execute_input":"2023-03-03T00:24:38.183080Z","iopub.status.idle":"2023-03-03T02:48:39.884938Z","shell.execute_reply.started":"2023-03-03T00:24:38.183047Z","shell.execute_reply":"2023-03-03T02:48:39.881637Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate\nmodel_small_1.eval()\n    \nrunning_loss = 0.0\nrunning_corrects = torch.zeros(15).to(device)\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tqdm(test_dataloader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model_small_1(inputs)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item() * inputs.size(0)\n        predicted_labels = torch.sigmoid(outputs) > 0.5\n        running_corrects += (predicted_labels == labels).sum(dim=0).float()\n        total_samples += inputs.size(0)\n\nepoch_loss = running_loss / total_samples\nepoch_acc = running_corrects / total_samples\n\nprint(f'Validation Loss: {epoch_loss:.4f} | Validation Acc: {epoch_acc.tolist()}')","metadata":{"execution":{"iopub.status.busy":"2023-03-03T02:48:39.889506Z","iopub.execute_input":"2023-03-03T02:48:39.889832Z","iopub.status.idle":"2023-03-03T02:55:12.906588Z","shell.execute_reply.started":"2023-03-03T02:48:39.889801Z","shell.execute_reply":"2023-03-03T02:55:12.905296Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run-6: Swin small with imagenet weights","metadata":{}},{"cell_type":"code","source":"# Use a pre-trained imagenet\n#model = swin_t(weights='DEFAULT')\n# Use no weights\nmodel_small_2 = swin_s(weights='DEFAULT')\n\n# Update the fully connected layer based on the number of classes in the dataset\n#model.fc = torch.nn.Linear(model.fc.in_features, len(ds_train.labels.info.class_names))\nmodel_small_2.head = torch.nn.Linear(out_features=15,in_features=768)\n\nmodel_small_2.to(device)\n\nprint(model_small_2)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model_small_2.parameters(), lr=1e-4)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-03T03:24:06.646813Z","iopub.execute_input":"2023-03-03T03:24:06.647962Z","iopub.status.idle":"2023-03-03T03:24:12.793433Z","shell.execute_reply.started":"2023-03-03T03:24:06.647919Z","shell.execute_reply":"2023-03-03T03:24:12.792248Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n#train\nmodel_small_2.train()\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    \n    running_loss = 0.0\n    for images, labels in tqdm(train_dataloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model_small_2(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n    epoch_loss = running_loss / len(train_dataset)\n    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))","metadata":{"execution":{"iopub.status.busy":"2023-03-03T03:24:34.853629Z","iopub.execute_input":"2023-03-03T03:24:34.854055Z","iopub.status.idle":"2023-03-03T05:45:39.163242Z","shell.execute_reply.started":"2023-03-03T03:24:34.854023Z","shell.execute_reply":"2023-03-03T05:45:39.161308Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate\nmodel_small_2.eval()\n    \nrunning_loss = 0.0\nrunning_corrects = torch.zeros(15).to(device)\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tqdm(test_dataloader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model_small_2(inputs)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item() * inputs.size(0)\n        predicted_labels = torch.sigmoid(outputs) > 0.5\n        running_corrects += (predicted_labels == labels).sum(dim=0).float()\n        total_samples += inputs.size(0)\n\nepoch_loss = running_loss / total_samples\nepoch_acc = running_corrects / total_samples\n\nprint(f'Validation Loss: {epoch_loss:.4f} | Validation Acc: {epoch_acc.tolist()}')","metadata":{"execution":{"iopub.status.busy":"2023-03-03T05:45:39.166404Z","iopub.execute_input":"2023-03-03T05:45:39.167661Z","iopub.status.idle":"2023-03-03T05:52:04.844039Z","shell.execute_reply.started":"2023-03-03T05:45:39.167619Z","shell.execute_reply":"2023-03-03T05:52:04.842758Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]}]}